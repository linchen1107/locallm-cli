#!/usr/bin/env python3
"""
LocalLM CLI - æœ¬åœ°æ¨¡å‹é©…å‹•çš„æª”æ¡ˆæ“ä½œå‘½ä»¤è¡Œå·¥å…·
ä¸€å€‹æœ€å°å¯è¡Œç”¢å“ (MVP)ï¼Œæä¾›æœ¬åœ°æ¨¡å‹é©…å‹•çš„æª”æ¡ˆæ“ä½œåŠŸèƒ½
"""

import sys
import os
import re
from pathlib import Path
from typing import List, Dict, Optional

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

from models import chat_stream, list_models, is_available
from tools import read_file, write_file, edit_file, file_exists, list_files, get_current_path


class LocalLMCLI:
    """LocalLM CLI ä¸»ç¨‹å¼é¡"""
    
    @staticmethod
    def levenshtein_distance(s1: str, s2: str) -> int:
        """è¨ˆç®—å…©å€‹å­—ç¬¦ä¸²çš„ç·¨è¼¯è·é›¢"""
        if len(s1) < len(s2):
            return LocalLMCLI.levenshtein_distance(s2, s1)
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        return previous_row[-1]
    
    def __init__(self, default_model: str = "llama3.2"):
        """
        åˆå§‹åŒ– CLI
        
        Args:
            default_model: é è¨­ä½¿ç”¨çš„æ¨¡å‹åç¨±
        """
        self.default_model = default_model
        self.conversation_history: List[Dict] = []
        self.running = True
        self.exit_count = 0  # ç”¨æ–¼è™•ç†é›™é‡ Ctrl+C é€€å‡º
        
    def print_banner(self):
        """é¡¯ç¤ºç¨‹å¼æ©«å¹…"""
        try:
            from rich.console import Console
            from rich.text import Text
            import pyfiglet
            
            console = Console()
            
            # ç”Ÿæˆ ASCII å­—é«”
            ascii_text = pyfiglet.figlet_format("LOCALLM")
            
            # æ‰‹å‹•å‰µå»ºæ¼¸å±¤æ•ˆæœ
            lines = ascii_text.strip().split('\n')
            total_lines = len(lines)
            
            print()
            for i, line in enumerate(lines):
                # è¨ˆç®—æ¼¸å±¤ä½ç½® (0.0 åˆ° 1.0)
                gradient_pos = i / max(1, total_lines - 1)
                
                # é’è‰²åˆ°æ©˜è‰²çš„æ¼¸å±¤
                if gradient_pos < 0.25:
                    color = "#00CFFF"  # é’è‰²
                elif gradient_pos < 0.5:
                    color = "#00A8FF"  # æ·ºè—
                elif gradient_pos < 0.75:
                    color = "#FFB347"  # æ·ºæ©˜
                else:
                    color = "#FF8C42"  # æ©˜è‰²
                
                console.print(line, style=f"bold {color}")
            
            # å‰¯æ¨™é¡Œå›ºå®šé¡è‰²ï¼šç²‰ç´…
            console.print("[bold #FF5FA2]æœ¬åœ°æ¨¡å‹ Ã— æ™ºèƒ½æª”æ¡ˆæ“ä½œ[/]", justify="center")
            print()
            
        except (ImportError, AttributeError) as e:
            # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨åŸæœ¬çš„ ASCII è—è¡“
            print()
            print("  â–ˆâ–ˆ      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆ      â–ˆâ–ˆ      â–ˆâ–ˆâ–ˆ    â–ˆâ–ˆâ–ˆ")
            print("  â–ˆâ–ˆ     â–ˆâ–ˆ    â–ˆâ–ˆ â–ˆâ–ˆ      â–ˆâ–ˆ   â–ˆâ–ˆ â–ˆâ–ˆ      â–ˆâ–ˆ      â–ˆâ–ˆâ–ˆâ–ˆ  â–ˆâ–ˆâ–ˆâ–ˆ")
            print("  â–ˆâ–ˆ     â–ˆâ–ˆ    â–ˆâ–ˆ â–ˆâ–ˆ      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ      â–ˆâ–ˆ      â–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ")
            print("  â–ˆâ–ˆ     â–ˆâ–ˆ    â–ˆâ–ˆ â–ˆâ–ˆ      â–ˆâ–ˆ   â–ˆâ–ˆ â–ˆâ–ˆ      â–ˆâ–ˆ      â–ˆâ–ˆ  â–ˆâ–ˆ  â–ˆâ–ˆ")
            print("  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ   â–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â–ˆâ–ˆ      â–ˆâ–ˆ")
            print()
            print("                 æœ¬åœ°æ¨¡å‹ Ã— æ™ºèƒ½æª”æ¡ˆæ“ä½œ")
            print()
        
        # ç°¡åŒ–ç‹€æ…‹é¡¯ç¤º
        status_line = "  "
        if is_available():
            models = list_models()
            model_count = len(models) if models else 0
            status_line += f"âœ“ Ollama ({model_count} models)"
        else:
            status_line += "âœ— Ollama offline"
        
        status_line += f"  â€¢  Model: {self.default_model}"
        
        # é¡¯ç¤ºç•¶å‰å·¥ä½œç›®éŒ„çš„ç›¸å°è·¯å¾‘æˆ–åç¨±
        current_path = Path(get_current_path())
        try:
            # å˜—è©¦é¡¯ç¤ºç›¸å°æ–¼ home ç›®éŒ„çš„è·¯å¾‘
            home_path = Path.home()
            if current_path.is_relative_to(home_path):
                relative_path = current_path.relative_to(home_path)
                display_path = f"~/{relative_path}" if str(relative_path) != "." else "~"
            else:
                display_path = current_path.name if current_path.name else str(current_path)
        except:
            display_path = current_path.name
            
        status_line += f"  â€¢  {display_path}"
        print(status_line)
        print()
        
        # ç°¡æ½”çš„ä½¿ç”¨æç¤º
        print("  Commands: /read /write /edit /create /list /models /switch /help /exit")
        print("  æˆ–ç›´æ¥å°è©±æå•ï¼Œä¾‹å¦‚: 'è«‹æ’°å¯«ä¸€å€‹ hello.txt'")
        print()
    
    def parse_command(self, input_text: str) -> tuple:
        """
        è§£æä½¿ç”¨è€…è¼¸å…¥çš„æŒ‡ä»¤
        
        Args:
            input_text: ä½¿ç”¨è€…è¼¸å…¥
            
        Returns:
            tuple: (å‘½ä»¤é¡å‹, åƒæ•¸åˆ—è¡¨)
        """
        input_text = input_text.strip()
        
        if not input_text.startswith('/'):
            return ('chat', [input_text])
        
        # ç§»é™¤é–‹é ­çš„ /
        command_line = input_text[1:]
        
        # ä½¿ç”¨æ­£è¦è¡¨é”å¼è§£ææŒ‡ä»¤å’Œåƒæ•¸
        # æ”¯æ´å¼•è™ŸåŒ…åœçš„åƒæ•¸
        parts = re.findall(r'"([^"]*)"|(\S+)', command_line)
        # æ­£è¦è¡¨é”å¼æœƒè¿”å›å…ƒçµ„ï¼Œéœ€è¦æå–éç©ºçš„éƒ¨åˆ†
        parts = [part[0] if part[0] else part[1] for part in parts]
        
        if not parts:
            return ('unknown', [])
        
        command = parts[0].lower()
        args = parts[1:] if len(parts) > 1 else []
        
        return (command, args)
    
    def handle_read_command(self, args: List[str]) -> None:
        """è™•ç†è®€å–æª”æ¡ˆæŒ‡ä»¤"""
        if not args:
            print("  âš  Usage: /read <file_path>")
            return
        
        file_path = args[0]
        try:
            content = read_file(file_path)
            print(f"\n  â”€â”€ {file_path} â”€â”€")
            print()
            print(content)
            print()
        except FileNotFoundError:
            print(f"  âœ— File not found: {file_path}")
        except PermissionError:
            print(f"  âœ— Permission denied: {file_path}")
        except Exception as e:
            print(f"  âœ— Error: {e}")
    
    def handle_write_command(self, args: List[str]) -> None:
        """è™•ç†å¯«å…¥æª”æ¡ˆæŒ‡ä»¤"""
        if len(args) < 2:
            print("  âš  Usage: /write <file_path> <content>")
            return
        
        file_path = args[0]
        content = ' '.join(args[1:])  # å°‡å‰©é¤˜åƒæ•¸åˆä½µç‚ºå…§å®¹
        
        try:
            write_file(file_path, content)
            print(f"  âœ“ Written: {file_path}")
        except PermissionError:
            print(f"  âœ— Permission denied: {file_path}")
        except Exception as e:
            print(f"  âœ— Error: {e}")
    
    def handle_edit_command(self, args: List[str]) -> None:
        """è™•ç†ç·¨è¼¯æª”æ¡ˆæŒ‡ä»¤"""
        if len(args) < 2:
            print("  âš  Usage: /edit <file_path> <content>")
            return
        
        file_path = args[0]
        new_content = ' '.join(args[1:])
        
        try:
            edit_file(file_path, new_content)
            print(f"  âœ“ Edited: {file_path}")
        except PermissionError:
            print(f"  âœ— Permission denied: {file_path}")
        except Exception as e:
            print(f"  âœ— Error: {e}")
    
    def handle_create_command(self, args: List[str]) -> None:
        """è™•ç†å‰µå»ºæª”æ¡ˆæŒ‡ä»¤"""
        if not args:
            print("  âš  Usage: /create <file_path> [content]")
            print("  If no content provided, AI will generate appropriate content")
            return
        
        file_path = args[0]
        
        # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
        if file_exists(file_path):
            response = input(f"  âš  File {file_path} already exists. Overwrite? (y/N): ")
            if response.lower() not in ['y', 'yes']:
                print("  âš  File creation cancelled")
                return
        
        if len(args) > 1:
            # æœ‰æä¾›å…§å®¹ï¼Œç›´æ¥ä½¿ç”¨
            content = ' '.join(args[1:])
            try:
                write_file(file_path, content)
                print(f"  âœ“ Created: {file_path}")
            except Exception as e:
                print(f"  âœ— Error creating file: {e}")
        else:
            # æ²’æœ‰æä¾›å…§å®¹ï¼Œä½¿ç”¨ AI ç”Ÿæˆ
            creation_request = f"create {file_path}"
            self.handle_file_creation_request(file_path, creation_request)
    
    def handle_list_command(self, args: List[str]) -> None:
        """è™•ç†åˆ—å‡ºæª”æ¡ˆæŒ‡ä»¤"""
        directory = args[0] if args else "."
        
        try:
            files = list_files(directory)
            if files:
                print(f"\n  Files in {directory}:")
                for i, file in enumerate(files, 1):
                    print(f"    {i:2d}. {file}")
                print()
            else:
                print(f"  Empty directory: {directory}")
        except FileNotFoundError:
            print(f"  âœ— Directory not found: {directory}")
        except Exception as e:
            print(f"  âœ— Error: {e}")
    
    def handle_models_command(self) -> None:
        """è™•ç†åˆ—å‡ºæ¨¡å‹æŒ‡ä»¤"""
        models = list_models()
        if models:
            print(f"\n  Available models ({len(models)}):")
            for i, model in enumerate(models, 1):
                name = model.get('name', 'unknown')
                size = model.get('size', 0)
                size_gb = size / (1024 * 1024 * 1024) if size else 0
                if size_gb >= 1:
                    size_str = f"{size_gb:.1f}GB"
                else:
                    size_mb = size / (1024 * 1024) if size else 0
                    size_str = f"{size_mb:.0f}MB"
                
                # æ¨™ç¤ºç•¶å‰ä½¿ç”¨çš„æ¨¡å‹
                current_marker = " â† current" if name == self.default_model else ""
                print(f"    {i:2d}. {name} ({size_str}){current_marker}")
            print()
            print("  ğŸ’¡ Use '/switch <name>' to switch models")
            print()
        else:
            print("  âœ— No models available")
    
    def handle_model_command(self, args: List[str]) -> None:
        """è™•ç†åˆ‡æ›æ¨¡å‹æŒ‡ä»¤"""
        if not args:
            print(f"  Current model: {self.default_model}")
            print("  ğŸ’¡ Use '/switch <name>' to switch models")
            print("  ğŸ’¡ Use '/switch <number>' to switch by number")
            print("  ğŸ’¡ Use '/models' to see available models")
            return
        
        new_model = args[0]
        available_models = list_models()
        model_names = [model.get('name', '') for model in available_models]
        
        # æª¢æŸ¥æ˜¯å¦æ˜¯æ•¸å­—é¸æ“‡
        if new_model.isdigit():
            model_index = int(new_model) - 1
            if 0 <= model_index < len(model_names):
                new_model = model_names[model_index]
            else:
                print(f"  âŒ Invalid model number: {new_model}")
                print(f"  ğŸ“ Available models: 1-{len(model_names)}")
                return
        
        # æ¨¡å‹åˆ¥åæ”¯æ´
        model_aliases = {
            'llama': 'llama3.2:latest',
            'llama3': 'llama3.2:latest',
            'mistral': 'mistral:7b',
            'codellama': 'codellama:13b',
            'gemma': 'gemma3:12b',
            'phi': 'phi4:14b',
            'qwen': 'qwen3:8b',
            'deepseek': 'deepseek-r1:8b'
        }
        
        # æª¢æŸ¥åˆ¥å
        if new_model.lower() in model_aliases:
            aliased_model = model_aliases[new_model.lower()]
            if aliased_model in model_names:
                new_model = aliased_model
                print(f"  ğŸ”— Using alias: {args[0]} â†’ {new_model}")
            else:
                print(f"  âš ï¸  Alias '{args[0]}' points to '{aliased_model}' but model not found")
        
        # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
        if new_model in model_names:
            old_model = self.default_model
            self.default_model = new_model
            print(f"  âœ… Model switched: {old_model} â†’ {new_model}")
            
            # æ¸…ç©ºå°è©±æ­·å²ï¼Œå› ç‚ºä¸åŒæ¨¡å‹å¯èƒ½æœ‰ä¸åŒçš„å°è©±æ ¼å¼
            if self.conversation_history:
                print("  ğŸ”„ Conversation history cleared for new model")
                self.conversation_history = []
        else:
            print(f"  âŒ Model '{new_model}' not found")
            print("  ğŸ’¡ Use '/models' to see available models")
            
            # æä¾›æ¨¡ç³ŠåŒ¹é…å»ºè­°
            suggestions = []
            
            # 0. é¦–å…ˆæª¢æŸ¥æ˜¯å¦èˆ‡åˆ¥åç›¸ä¼¼
            for alias, full_name in model_aliases.items():
                if self.levenshtein_distance(new_model.lower(), alias) <= 2 and full_name in model_names:
                    suggestions.append(f"{full_name} (alias: {alias})")
            
            # 1. æª¢æŸ¥æ˜¯å¦åŒ…å«éƒ¨åˆ†åŒ¹é…
            for name in model_names:
                if new_model.lower() in name.lower() or name.lower() in new_model.lower():
                    if name not in [s.split(' (alias:')[0] for s in suggestions]:  # é¿å…é‡è¤‡
                        suggestions.append(name)
            
            # 2. å¦‚æœæ²’æœ‰éƒ¨åˆ†åŒ¹é…ï¼Œå˜—è©¦ç›¸ä¼¼åº¦åŒ¹é…
            if not suggestions:
                for name in model_names:
                    # ç°¡å–®çš„ç›¸ä¼¼åº¦è¨ˆç®—ï¼šè¨ˆç®—ç›¸åŒå­—ç¬¦çš„æ¯”ä¾‹
                    def similarity(s1, s2):
                        s1, s2 = s1.lower(), s2.lower()
                        common = sum(1 for c in s1 if c in s2)
                        return common / max(len(s1), len(s2))
                    
                    # å¦‚æœç›¸ä¼¼åº¦è¶…é 60%ï¼ŒåŠ å…¥å»ºè­°
                    if similarity(new_model, name) > 0.6:
                        suggestions.append(name)
            
            # 3. ç‰¹åˆ¥æª¢æŸ¥æ‹¼å¯«éŒ¯èª¤çš„æƒ…æ³
            if not suggestions:
                for name in model_names:
                    name_base = name.split(':')[0].lower()
                    input_base = new_model.split(':')[0].lower()
                    
                    # å¦‚æœç·¨è¼¯è·é›¢ <= 2ï¼ŒåŠ å…¥å»ºè­°
                    distance = self.levenshtein_distance(input_base, name_base)
                    if distance <= 2 and len(input_base) >= 3:
                        suggestions.append(name)
            
            if suggestions:
                print("  ğŸ“ Did you mean:")
                for suggestion in suggestions[:3]:  # æœ€å¤šé¡¯ç¤º3å€‹å»ºè­°
                    print(f"     - {suggestion}")
            
            # é¡¯ç¤ºå¯ç”¨çš„åˆ¥å
            print("  ğŸ”— Available aliases:")
            print("     llama, mistral, codellama, gemma, phi, qwen, deepseek")
    
    def handle_switch_command(self, args: List[str]) -> None:
        """è™•ç†åˆ‡æ›æ¨¡å‹æŒ‡ä»¤ (switch åˆ¥å)"""
        self.handle_model_command(args)
    
    def handle_chat_command(self, message: str) -> None:
        """è™•ç†å°è©±æŒ‡ä»¤"""
        if not message.strip():
            return
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«æª”æ¡ˆæ“ä½œçš„è‡ªç„¶èªè¨€è«‹æ±‚
        if self.should_use_file_tools(message):
            self.handle_natural_file_operation(message)
            return
        
        # æ·»åŠ ä½¿ç”¨è€…è¨Šæ¯åˆ°å°è©±æ­·å²
        self.conversation_history.append({
            "role": "user",
            "content": message
        })
        
        print(f"\n  {self.default_model} â€º")
        print()
        
        # ä½¿ç”¨æµå¼è¼¸å‡º
        assistant_response = ""
        try:
            for chunk in chat_stream(self.default_model, self.conversation_history):
                print(chunk, end='', flush=True)
                assistant_response += chunk
            
            print("\n")  # é›™æ›è¡Œ
            
            # æ·»åŠ åŠ©æ‰‹å›æ‡‰åˆ°å°è©±æ­·å²
            if assistant_response:
                self.conversation_history.append({
                    "role": "assistant",
                    "content": assistant_response
                })
                
        except KeyboardInterrupt:
            print("\n  âš  Interrupted\n")
        except Exception as e:
            print(f"\n  âœ— Error: {e}\n")
    
    def should_use_file_tools(self, message: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦æ‡‰è©²ä½¿ç”¨æª”æ¡ˆå·¥å…·"""
        file_keywords = [
            'è®€å–', 'è®€', 'read', 'æª”æ¡ˆå…§å®¹',
            'å¯«å…¥', 'å¯«', 'write', 'å»ºç«‹æª”æ¡ˆ', 'å‰µå»ºæª”æ¡ˆ', 'æ–°å¢æª”æ¡ˆ',
            'ç·¨è¼¯', 'edit', 'ä¿®æ”¹æª”æ¡ˆ',
            'åˆ†ææª”æ¡ˆ', 'æŸ¥çœ‹æª”æ¡ˆ', 'é¡¯ç¤ºæª”æ¡ˆ',
            'æ’°å¯«', 'ç”¢ç”Ÿ', 'generate', 'create', 'è£½ä½œ'
        ]
        
        message_lower = message.lower()
        return any(keyword in message_lower for keyword in file_keywords)
    
    def handle_natural_file_operation(self, message: str) -> None:
        """è™•ç†è‡ªç„¶èªè¨€çš„æª”æ¡ˆæ“ä½œè«‹æ±‚"""
        # ç°¡å–®çš„æª”æ¡ˆè·¯å¾‘æå–
        # é€™è£¡å¯ä»¥ä½¿ç”¨æ›´è¤‡é›œçš„ NLP æŠ€è¡“ï¼Œä½†ç‚ºäº† MVP ä¿æŒç°¡å–®
        
        # å°‹æ‰¾æª”æ¡ˆè·¯å¾‘æ¨¡å¼
        import re
        path_patterns = [
            r'([a-zA-Z]:[\\\/][^"\s]+)',  # Windows çµ•å°è·¯å¾‘
            r'([\.\/][^"\s]+\.[a-zA-Z0-9]+)',  # ç›¸å°è·¯å¾‘
            r'([a-zA-Z_][a-zA-Z0-9_]*\.[a-zA-Z0-9]+)',  # ç°¡å–®æª”å
        ]
        
        found_paths = []
        for pattern in path_patterns:
            matches = re.findall(pattern, message)
            found_paths.extend(matches)
        
        if not found_paths:
            print("âŒ ç„¡æ³•å¾è¨Šæ¯ä¸­è­˜åˆ¥æª”æ¡ˆè·¯å¾‘")
            print("è«‹ä½¿ç”¨æ˜ç¢ºçš„æŒ‡ä»¤æ ¼å¼ï¼Œæˆ–åŒ…å«å…·é«”çš„æª”æ¡ˆè·¯å¾‘")
            return
        
        file_path = found_paths[0]  # ä½¿ç”¨ç¬¬ä¸€å€‹æ‰¾åˆ°çš„è·¯å¾‘
        
        # åˆ¤æ–·æ“ä½œé¡å‹
        message_lower = message.lower()
        
        if any(word in message_lower for word in ['è®€å–', 'è®€', 'read', 'åˆ†æ', 'æŸ¥çœ‹', 'é¡¯ç¤º']):
            print(f"  â†’ Reading {file_path}")
            self.handle_read_command([file_path])
        elif any(word in message_lower for word in ['æ’°å¯«', 'ç”¢ç”Ÿ', 'generate', 'create', 'è£½ä½œ', 'å»ºç«‹', 'å‰µå»º', 'æ–°å¢']):
            print(f"  â†’ Creating {file_path}")
            self.handle_file_creation_request(file_path, message)
        elif any(word in message_lower for word in ['å¯«å…¥', 'å¯«', 'write', 'ç·¨è¼¯', 'edit', 'ä¿®æ”¹']):
            print(f"  â†’ Writing to {file_path}")
            # å°æ–¼å¯«å…¥æ“ä½œï¼Œæˆ‘å€‘éœ€è¦å¾è¨Šæ¯ä¸­æå–å…§å®¹
            self.handle_write_from_message(file_path, message)
        else:
            print("  âš  Unable to determine file operation")
            print("  Please use explicit commands")
    
    def handle_file_creation_request(self, file_path: str, original_message: str) -> None:
        """è™•ç†æª”æ¡ˆå‰µå»ºè«‹æ±‚ï¼Œä½¿ç”¨ AI ç”Ÿæˆå…§å®¹"""
        print(f"  ğŸ¤– Generating content for {file_path}...")
        
        # æº–å‚™ AI æç¤º
        file_extension = Path(file_path).suffix.lower()
        
        # æ ¹æ“šæª”æ¡ˆé¡å‹æº–å‚™æç¤º
        if file_extension == '.txt':
            prompt = f"è«‹æ ¹æ“šä½¿ç”¨è€…çš„è¦æ±‚å‰µå»ºä¸€å€‹æ–‡å­—æª”æ¡ˆçš„å…§å®¹ã€‚ä½¿ç”¨è€…çš„è¦æ±‚æ˜¯ï¼š{original_message}\n\nè«‹ç›´æ¥æä¾›æª”æ¡ˆå…§å®¹ï¼Œä¸è¦åŠ ä¸Šå…¶ä»–èªªæ˜æ–‡å­—ã€‚"
        elif file_extension == '.py':
            prompt = f"è«‹æ ¹æ“šä½¿ç”¨è€…çš„è¦æ±‚å‰µå»ºä¸€å€‹ Python ç¨‹å¼æª”æ¡ˆã€‚ä½¿ç”¨è€…çš„è¦æ±‚æ˜¯ï¼š{original_message}\n\nè«‹æä¾›å®Œæ•´çš„ Python ç¨‹å¼ç¢¼ï¼ŒåŒ…å«é©ç•¶çš„è¨»è§£ã€‚"
        elif file_extension == '.md':
            prompt = f"è«‹æ ¹æ“šä½¿ç”¨è€…çš„è¦æ±‚å‰µå»ºä¸€å€‹ Markdown æª”æ¡ˆã€‚ä½¿ç”¨è€…çš„è¦æ±‚æ˜¯ï¼š{original_message}\n\nè«‹æä¾›æ ¼å¼åŒ–çš„ Markdown å…§å®¹ã€‚"
        elif file_extension == '.html':
            prompt = f"è«‹æ ¹æ“šä½¿ç”¨è€…çš„è¦æ±‚å‰µå»ºä¸€å€‹ HTML æª”æ¡ˆã€‚ä½¿ç”¨è€…çš„è¦æ±‚æ˜¯ï¼š{original_message}\n\nè«‹æä¾›å®Œæ•´çš„ HTML çµæ§‹ã€‚"
        elif file_extension == '.js':
            prompt = f"è«‹æ ¹æ“šä½¿ç”¨è€…çš„è¦æ±‚å‰µå»ºä¸€å€‹ JavaScript æª”æ¡ˆã€‚ä½¿ç”¨è€…çš„è¦æ±‚æ˜¯ï¼š{original_message}\n\nè«‹æä¾›å®Œæ•´çš„ JavaScript ç¨‹å¼ç¢¼ã€‚"
        elif file_extension == '.json':
            prompt = f"è«‹æ ¹æ“šä½¿ç”¨è€…çš„è¦æ±‚å‰µå»ºä¸€å€‹ JSON æª”æ¡ˆã€‚ä½¿ç”¨è€…çš„è¦æ±‚æ˜¯ï¼š{original_message}\n\nè«‹æä¾›æœ‰æ•ˆçš„ JSON æ ¼å¼å…§å®¹ã€‚"
        else:
            prompt = f"è«‹æ ¹æ“šä½¿ç”¨è€…çš„è¦æ±‚å‰µå»ºæª”æ¡ˆå…§å®¹ã€‚ä½¿ç”¨è€…çš„è¦æ±‚æ˜¯ï¼š{original_message}\n\nè«‹æä¾›é©åˆçš„æª”æ¡ˆå…§å®¹ã€‚"
        
        # ä½¿ç”¨ AI ç”Ÿæˆå…§å®¹
        try:
            messages = [{"role": "user", "content": prompt}]
            
            print(f"  {self.default_model} â€º")
            print()
            
            generated_content = ""
            for chunk in chat_stream(self.default_model, messages):
                print(chunk, end='', flush=True)
                generated_content += chunk
            
            print("\n")
            
            if generated_content.strip():
                # æ¸…ç†ç”Ÿæˆçš„å…§å®¹ï¼ˆç§»é™¤å¯èƒ½çš„å‰å¾Œèªªæ˜æ–‡å­—ï¼‰
                content_lines = generated_content.strip().split('\n')
                
                # å¦‚æœç¬¬ä¸€è¡Œçœ‹èµ·ä¾†åƒèªªæ˜æ–‡å­—ï¼Œè·³éå®ƒ
                if content_lines and any(word in content_lines[0].lower() for word in ['é€™æ˜¯', 'ä»¥ä¸‹æ˜¯', 'here is', 'here\'s']):
                    content_lines = content_lines[1:]
                
                # å¦‚æœæœ€å¾Œå¹¾è¡Œçœ‹èµ·ä¾†åƒèªªæ˜æ–‡å­—ï¼Œç§»é™¤å®ƒå€‘
                while content_lines and any(word in content_lines[-1].lower() for word in ['å¸Œæœ›', 'é€™å€‹', 'ä»¥ä¸Š', 'è«‹æ³¨æ„']):
                    content_lines.pop()
                
                final_content = '\n'.join(content_lines).strip()
                
                if final_content:
                    # å¯«å…¥æª”æ¡ˆ
                    write_file(file_path, final_content)
                    print(f"  âœ“ Created: {file_path}")
                    print(f"  ğŸ“„ Content length: {len(final_content)} characters")
                else:
                    print(f"  âš  Generated content is empty")
            else:
                print(f"  âš  No content generated")
                
        except Exception as e:
            print(f"  âœ— Error generating content: {e}")
    
    def handle_write_from_message(self, file_path: str, message: str) -> None:
        """å¾è¨Šæ¯ä¸­æå–å…§å®¹ä¸¦å¯«å…¥æª”æ¡ˆ"""
        # å˜—è©¦å¾è¨Šæ¯ä¸­æå–è¦å¯«å…¥çš„å…§å®¹
        import re
        
        # å°‹æ‰¾å¼•è™Ÿå…§çš„å…§å®¹
        quoted_content = re.findall(r'"([^"]*)"', message)
        if quoted_content:
            content = quoted_content[0]
            write_file(file_path, content)
            print(f"  âœ“ Written: {file_path}")
            return
        
        # å¦‚æœæ²’æœ‰å¼•è™Ÿï¼Œä½¿ç”¨ AI ç”Ÿæˆå…§å®¹
        print(f"  ğŸ¤– No explicit content found, generating content...")
        self.handle_file_creation_request(file_path, message)
    
    def handle_help_command(self) -> None:
        """é¡¯ç¤ºå¹«åŠ©è³‡è¨Š"""
        print("\n")
        print("  â•­â”€ Commands â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®")
        print("  â”‚                                    â”‚")
        print("  â”‚  /read <path>     Read file        â”‚")
        print("  â”‚  /write <path>    Write file       â”‚")  
        print("  â”‚  /edit <path>     Edit file        â”‚")
        print("  â”‚  /create <path>   Create file      â”‚")
        print("  â”‚  /list [dir]      List files       â”‚")
        print("  â”‚  /pwd             Show path        â”‚")
        print("  â”‚  /models          Show models      â”‚")
        print("  â”‚  /switch <name>   Switch model     â”‚")
        print("  â”‚  /help            This help        â”‚")
        print("  â”‚  /exit            Exit program     â”‚")
        print("  â”‚                                    â”‚")
        print("  â”‚  Or just ask questions naturally   â”‚")
        print("  â”‚                                    â”‚")
        print("  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯")
        print()
    
    def run(self):
        """åŸ·è¡Œä¸»ç¨‹å¼å¾ªç’°"""
        self.print_banner()
        
        while self.running:
            try:
                # é¡¯ç¤ºæç¤ºç¬¦
                user_input = input("  â€º ").strip()
                
                if not user_input:
                    continue
                
                # è§£ææŒ‡ä»¤
                command, args = self.parse_command(user_input)
                
                # åŸ·è¡Œå°æ‡‰çš„è™•ç†å‡½æ•¸
                if command == 'exit' or command == 'quit':
                    print("\n  Goodbye! ğŸ‘‹")
                    import os
                    os._exit(0)
                elif command == 'help':
                    self.handle_help_command()
                elif command == 'read':
                    self.handle_read_command(args)
                elif command == 'write':
                    self.handle_write_command(args)
                elif command == 'edit':
                    self.handle_edit_command(args)
                elif command == 'create' or command == 'new':
                    self.handle_create_command(args)
                elif command == 'list' or command == 'ls':
                    self.handle_list_command(args)
                elif command == 'pwd':
                    print(f"  Current: {get_current_path()}")
                elif command == 'models':
                    self.handle_models_command()
                elif command == 'switch' or command == 'model':
                    self.handle_model_command(args)
                elif command == 'chat':
                    self.handle_chat_command(args[0] if args else "")
                else:
                    print(f"  âœ— Unknown command: {command}")
                    print("  Type /help for available commands")
                
                self.exit_count = 0  # é‡ç½®é€€å‡ºè¨ˆæ•¸
                
            except KeyboardInterrupt:
                self.exit_count += 1
                if self.exit_count >= 2:
                    print("\n\n  Goodbye! ğŸ‘‹")
                    import os
                    os._exit(0)
                else:
                    print(f"\n  âš  Press Ctrl+C again to exit")
            except EOFError:
                print("\n\n  Goodbye! ğŸ‘‹")
                import os
                os._exit(0)
            except Exception as e:
                print(f"  âœ— Unexpected error: {e}")


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="LocalLM CLI - æœ¬åœ°æ¨¡å‹æª”æ¡ˆæ“ä½œå·¥å…·")
    parser.add_argument(
        '--model', '-m',
        default='llama3.2',
        help='æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹åç¨± (é è¨­: llama3.2)'
    )
    
    args = parser.parse_args()
    
    # å»ºç«‹ä¸¦åŸ·è¡Œ CLI
    cli = LocalLMCLI(default_model=args.model)
    cli.run()


if __name__ == "__main__":
    main()